{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root=\"../data/TUDataset\", name='COLLAB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About Collab Dataset\n",
    "COLLAB is a scientific collaboration dataset. A graph corresponds to a researcher’s ego network, i.e., the researcher and its collaborators are nodes and an edge indicates collaboration between two researchers. A researcher’s ego network has three possible labels, i.e., High Energy Physics, Condensed Matter Physics, and Astro Physics, which are the fields that the researcher belongs to. The dataset has 5,000 graphs and each graph has label 0, 1, or 2.\n",
    "https://paperswithcode.com/dataset/collab \n",
    "https://networkrepository.com/COLLAB.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: COLLAB(5000)\n",
      "Num Graphs: 5000\n",
      "Num Nodes: 372474\n",
      "Num classes: 3\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset: {dataset}')\n",
    "print(f'Num Graphs: {len(dataset)}')\n",
    "print(f'Num Nodes: {dataset.num_nodes}')\n",
    "print(f'Num classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42., 46., 39., 45.,  8., 45., 39., 45., 42., 45.,  7., 45., 45., 45.,\n",
       "        42., 47., 45., 45., 45., 45., 47., 42., 45., 45., 47., 45., 39., 45.,\n",
       "        42., 45., 45., 45., 45., 45., 45., 45., 45., 45., 45., 47., 47., 45.,\n",
       "        45., 45., 45., 45., 45., 42.])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_geometric.utils.degree(dataset[4].edge_index[0], dataset[4].num_nodes)\n",
    "\n",
    "# dataset[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set CUDA\n",
    "device = \"cuda:0\" if (torch.cuda.is_available()) else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_degree = 0\n",
    "for data in dataset:\n",
    "    deg = torch_geometric.utils.degree(data.edge_index[1], num_nodes=data.num_nodes)\n",
    "    max_degree = max(max_degree, max(deg).item())\n",
    "# assign to one hot degree for each data (OneHotDegree receive maximum degree parameter)\n",
    "dataset.transform = torch_geometric.transforms.OneHotDegree(int(max_degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_dataset = []\n",
    "for g in dataset:\n",
    "    cuda_dataset.append(g.to(torch.device(device), non_blocking=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_dataset[0].x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COLLAB(5000)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = 0.8\n",
    "seed = 123\n",
    "\n",
    "num_split = round(len(dataset) * split)\n",
    "torch.manual_seed(seed)\n",
    "dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  4000\n",
      "Test:  1000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = cuda_dataset[:num_split]\n",
    "test_dataset = cuda_dataset[num_split:]\n",
    "print('Train: ', len(train_dataset))\n",
    "print('Test: ', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Graph neural network models\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# pooling method (for readout layer)\n",
    "from torch_geometric.nn import global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, data, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        # seed\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = GCNConv(data.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, data.num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)        \n",
    "        \n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data.x.to(torch.device(device)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for data in loader:\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return out, loss\n",
    "\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "    return correct/len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(492, 42)\n",
       "  (conv2): GCNConv(42, 42)\n",
       "  (conv3): GCNConv(42, 42)\n",
       "  (lin): Linear(in_features=42, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCN(dataset, 42)\n",
    "model.to(torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_acc: 0.7937 loss: 0.3320 test_acc: 0.4620\n",
      "epoch: 2 train_acc: 0.7993 loss: 0.6185 test_acc: 0.6540\n",
      "epoch: 3 train_acc: 0.8043 loss: 0.4405 test_acc: 0.5270\n",
      "epoch: 4 train_acc: 0.8070 loss: 0.4485 test_acc: 0.6410\n",
      "epoch: 5 train_acc: 0.8087 loss: 0.3878 test_acc: 0.6620\n",
      "epoch: 6 train_acc: 0.8340 loss: 0.3902 test_acc: 0.6420\n",
      "epoch: 7 train_acc: 0.8297 loss: 0.3311 test_acc: 0.5400\n",
      "epoch: 8 train_acc: 0.8498 loss: 0.4273 test_acc: 0.5910\n",
      "epoch: 9 train_acc: 0.8417 loss: 0.6867 test_acc: 0.6750\n",
      "epoch: 10 train_acc: 0.8365 loss: 0.2806 test_acc: 0.5830\n",
      "epoch: 11 train_acc: 0.8605 loss: 0.2475 test_acc: 0.5760\n",
      "epoch: 12 train_acc: 0.8670 loss: 0.4175 test_acc: 0.5640\n",
      "epoch: 13 train_acc: 0.8622 loss: 0.3740 test_acc: 0.6680\n",
      "epoch: 14 train_acc: 0.8698 loss: 0.3088 test_acc: 0.5400\n",
      "epoch: 15 train_acc: 0.8710 loss: 0.1967 test_acc: 0.4970\n",
      "epoch: 16 train_acc: 0.8792 loss: 0.1939 test_acc: 0.6420\n",
      "epoch: 17 train_acc: 0.8852 loss: 0.4456 test_acc: 0.6760\n",
      "epoch: 18 train_acc: 0.8752 loss: 0.4041 test_acc: 0.5510\n",
      "epoch: 19 train_acc: 0.8812 loss: 0.2354 test_acc: 0.5490\n",
      "epoch: 20 train_acc: 0.8725 loss: 0.2325 test_acc: 0.5580\n",
      "epoch: 21 train_acc: 0.8602 loss: 0.2923 test_acc: 0.5690\n",
      "epoch: 22 train_acc: 0.8705 loss: 0.4186 test_acc: 0.5230\n",
      "epoch: 23 train_acc: 0.8925 loss: 0.2285 test_acc: 0.5630\n",
      "epoch: 24 train_acc: 0.8948 loss: 0.2104 test_acc: 0.5750\n",
      "epoch: 25 train_acc: 0.8942 loss: 0.3177 test_acc: 0.6110\n"
     ]
    }
   ],
   "source": [
    "list_loss = []\n",
    "list_train_acc = []\n",
    "list_test_acc = []\n",
    "\n",
    "for epoch in range(0, 25):\n",
    "    out, loss = train(model, train_loader)\n",
    "    train_acc = test(model, train_loader)\n",
    "    test_acc = test(model, test_loader)\n",
    "    \n",
    "    list_train_acc.append(round(train_acc, 4))\n",
    "    list_test_acc.append(round(test_acc, 4))\n",
    "    list_loss.append(round(loss.item(), 4))\n",
    "\n",
    "    print(f\"epoch: {epoch+1} train_acc: {train_acc:.4f} loss: {loss:.4f} test_acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free cuda memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "model.cpu()\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
