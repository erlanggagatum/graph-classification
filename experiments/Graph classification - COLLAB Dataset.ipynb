{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root=\"../data/TUDataset\", name='COLLAB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About Collab Dataset\n",
    "COLLAB is a scientific collaboration dataset. A graph corresponds to a researcher’s ego network, i.e., the researcher and its collaborators are nodes and an edge indicates collaboration between two researchers. A researcher’s ego network has three possible labels, i.e., High Energy Physics, Condensed Matter Physics, and Astro Physics, which are the fields that the researcher belongs to. The dataset has 5,000 graphs and each graph has label 0, 1, or 2.\n",
    "https://paperswithcode.com/dataset/collab \n",
    "https://networkrepository.com/COLLAB.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: COLLAB(5000)\n",
      "Num Graphs: 5000\n",
      "Num Nodes: 372474\n",
      "Num classes: 3\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset: {dataset}')\n",
    "print(f'Num Graphs: {len(dataset)}')\n",
    "print(f'Num Nodes: {dataset.num_nodes}')\n",
    "print(f'Num classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42., 46., 39., 45.,  8., 45., 39., 45., 42., 45.,  7., 45., 45., 45.,\n",
       "        42., 47., 45., 45., 45., 45., 47., 42., 45., 45., 47., 45., 39., 45.,\n",
       "        42., 45., 45., 45., 45., 45., 45., 45., 45., 45., 45., 47., 47., 45.,\n",
       "        45., 45., 45., 45., 45., 42.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_geometric.utils.degree(dataset[4].edge_index[0], dataset[4].num_nodes)\n",
    "\n",
    "# dataset[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set CUDA\n",
    "device = \"cuda:0\" if (torch.cuda.is_available()) else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_degree = 0\n",
    "for data in dataset:\n",
    "    deg = torch_geometric.utils.degree(data.edge_index[1], num_nodes=data.num_nodes)\n",
    "    max_degree = max(max_degree, max(deg).item())\n",
    "# assign to one hot degree for each data (OneHotDegree receive maximum degree parameter)\n",
    "dataset.transform = torch_geometric.transforms.OneHotDegree(int(max_degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_dataset = []\n",
    "for g in dataset:\n",
    "    cuda_dataset.append(g.to(torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_dataset[0].x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COLLAB(5000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = 0.8\n",
    "seed = 123\n",
    "\n",
    "num_split = round(len(dataset) * split)\n",
    "torch.manual_seed(seed)\n",
    "dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  4000\n",
      "Test:  1000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = cuda_dataset[:num_split]\n",
    "test_dataset = cuda_dataset[num_split:]\n",
    "print('Train: ', len(train_dataset))\n",
    "print('Test: ', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Graph neural network models\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "\n",
    "# pooling method (for readout layer)\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import global_max_pool\n",
    "from torch_geometric.nn import SAGPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, data, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        # seed\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = GCNConv(data.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, data.num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # x = x.relu()\n",
    "        # x = self.conv3(x, edge_index)        \n",
    "        \n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GraphSAGE implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, data, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        # seed\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = GraphSAGE(data.num_node_features, hidden_channels, num_layers=2)\n",
    "        # self.conv2 = GraphSAGE(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, data.num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        # x = self.conv2(x, edge_index)\n",
    "        # x = x.elu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/inyeoplee77/SAGPool/blob/master/networks.py\n",
    "# class GCN(torch.nn.Module):\n",
    "#     def __init__(self, data, hidden_channels):\n",
    "#         super(GCN, self).__init__()\n",
    "#         # seed\n",
    "#         torch.manual_seed(42)\n",
    "#         self.conv1 = GCNConv(data.num_node_features, hidden_channels)\n",
    "#         self.pool1 = SAGPooling(hidden_channels, ratio=0.5)\n",
    "#         self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "#         self.pool2 = SAGPooling(hidden_channels, ratio=0.5)\n",
    "#         self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "#         self.pool3 = SAGPooling(hidden_channels, ratio=0.5)\n",
    "        \n",
    "#         self.lin1 = Linear(hidden_channels*2, hidden_channels)\n",
    "#         self.lin2 = Linear(hidden_channels, hidden_channels//2)\n",
    "#         self.lin3 = Linear(hidden_channels//2, data.num_classes)\n",
    "\n",
    "#     def forward(self, x, edge_index, batch):\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "#         x1 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "        \n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "#         x2 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "        \n",
    "#         x = self.conv3(x, edge_index)\n",
    "#         x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "#         x3 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "#         # x = global_max_pool(x, batch)\n",
    "#         x = x1 + x2 + x3\n",
    "        \n",
    "#         x = F.relu(self.lin1(x))\n",
    "#         x = F.dropout(x, p=0.5, training=self.training)\n",
    "#         x = F.relu(self.lin2(x))\n",
    "#         x = self.lin3(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data.x.to(torch.device(device)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for data in loader:\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return out, loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "    return correct/len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GraphSAGE(492, 64, num_layers=2)\n",
       "  (lin): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCN(dataset, 64)\n",
    "model.to(torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BasicGNN.forward() got an unexpected keyword argument 'batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sclab\\Documents\\Projects\\graph-classification\\experiments\\Graph classification - COLLAB Dataset.ipynb Cell 23\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sclab/Documents/Projects/graph-classification/experiments/Graph%20classification%20-%20COLLAB%20Dataset.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m list_test_acc \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sclab/Documents/Projects/graph-classification/experiments/Graph%20classification%20-%20COLLAB%20Dataset.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m10\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sclab/Documents/Projects/graph-classification/experiments/Graph%20classification%20-%20COLLAB%20Dataset.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     out, loss \u001b[39m=\u001b[39m train(model, train_loader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sclab/Documents/Projects/graph-classification/experiments/Graph%20classification%20-%20COLLAB%20Dataset.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     train_acc \u001b[39m=\u001b[39m test(model, train_loader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sclab/Documents/Projects/graph-classification/experiments/Graph%20classification%20-%20COLLAB%20Dataset.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     test_acc \u001b[39m=\u001b[39m test(model, test_loader)\n",
      "\u001b[1;32mc:\\Users\\sclab\\Documents\\Projects\\graph-classification\\experiments\\Graph classification - COLLAB Dataset.ipynb Cell 23\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sclab/Documents/Projects/graph-classification/experiments/Graph%20classification%20-%20COLLAB%20Dataset.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sclab/Documents/Projects/graph-classification/experiments/Graph%20classification%20-%20COLLAB%20Dataset.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sclab/Documents/Projects/graph-classification/experiments/Graph%20classification%20-%20COLLAB%20Dataset.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     out \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index, data\u001b[39m.\u001b[39mbatch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sclab/Documents/Projects/graph-classification/experiments/Graph%20classification%20-%20COLLAB%20Dataset.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(out, data\u001b[39m.\u001b[39my)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sclab/Documents/Projects/graph-classification/experiments/Graph%20classification%20-%20COLLAB%20Dataset.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\sclab\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\sclab\\Documents\\Projects\\graph-classification\\experiments\\Graph classification - COLLAB Dataset.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sclab/Documents/Projects/graph-classification/experiments/Graph%20classification%20-%20COLLAB%20Dataset.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index, batch):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sclab/Documents/Projects/graph-classification/experiments/Graph%20classification%20-%20COLLAB%20Dataset.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x, edge_index, batch\u001b[39m=\u001b[39mbatch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sclab/Documents/Projects/graph-classification/experiments/Graph%20classification%20-%20COLLAB%20Dataset.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mrelu()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sclab/Documents/Projects/graph-classification/experiments/Graph%20classification%20-%20COLLAB%20Dataset.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# x = self.conv2(x, edge_index)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sclab/Documents/Projects/graph-classification/experiments/Graph%20classification%20-%20COLLAB%20Dataset.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# x = x.elu()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sclab\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: BasicGNN.forward() got an unexpected keyword argument 'batch'"
     ]
    }
   ],
   "source": [
    "list_loss = []\n",
    "list_train_acc = []\n",
    "list_test_acc = []\n",
    "\n",
    "for epoch in range(0, 10):\n",
    "    out, loss = train(model, train_loader)\n",
    "    train_acc = test(model, train_loader)\n",
    "    test_acc = test(model, test_loader)\n",
    "    \n",
    "    list_train_acc.append(round(train_acc, 4))\n",
    "    list_test_acc.append(round(test_acc, 4))\n",
    "    list_loss.append(round(loss.item(), 4))\n",
    "\n",
    "    print(f\"epoch: {epoch+1} train_acc: {train_acc:.4f} loss: {loss:.4f} test_acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free cuda memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "model.cpu()\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 190668], y=[64], num_nodes=4960, x=[4960, 492], batch=[4960], ptr=[65])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for train in train_loader:\n",
    "    print(train)\n",
    "    print(train.x)\n",
    "    \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
